{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SpecialFuseNetModel\n",
    "from data_manager import rgbd_gradients_dataset, rgbd_gradients_dataloader\n",
    "from train import FuseNetTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomav\\Documents\\GitHub\\cs236781-project\\data/nyuv2\n"
     ]
    }
   ],
   "source": [
    "CWD             = os.getcwd()\n",
    "DATASET_DIR     = os.path.join(CWD,'data/nyuv2')\n",
    "print(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE       = (224,224)\n",
    "TRAIN_TEST_RATIO = 0.5#0.9\n",
    "BATCH_SIZE       = 4\n",
    "NUM_WORKERS      = 4\n",
    "\n",
    "BETAS        = (0.9,0.99)\n",
    "LR           = 0.001\n",
    "MOMENTUM     = 0.9\n",
    "WEIGHT_DECAY = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_tf = T.Compose([\n",
    "    # Resize to constant spatial dimensions\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    # PIL.Image -> torch.Tensor\n",
    "    T.ToTensor(),\n",
    "    # Dynamic range [0,1] -> [-1, 1]\n",
    "    T.Normalize(mean=(.5,.5,.5), std=(.5,.5,.5)),\n",
    "])\n",
    "depth_tf = T.Compose([\n",
    "    # Resize to constant spatial dimensions\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    # PIL.Image -> torch.Tensor\n",
    "    T.ToTensor(),\n",
    "    # Dynamic range [0,1] -> [-1, 1]\n",
    "    T.Normalize(mean=(.5,), std=(.5,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_grads_ds = rgbd_gradients_dataset(root=DATASET_DIR,rgb_transforms=rgb_tf,depth_transforms=depth_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train,dl_test = rgbd_gradients_dataloader(root=DATASET_DIR,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             num_workers=NUM_WORKERS,\n",
    "                                             train_test_ration=TRAIN_TEST_RATIO,\n",
    "                                             rgb_transforms=rgb_tf,depth_transforms=depth_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images in dataset folder.\n"
     ]
    }
   ],
   "source": [
    "# _ = plot.rgbd_gradients_dataset_first_n(dataset=rgbd_grads_ds,n=5)\n",
    "print(f'Found {len(rgbd_grads_ds)} images in dataset folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(dl_train))\n",
    "rgb_size = tuple(sample_batch['rgb'].shape[1:])\n",
    "depth_size = tuple(sample_batch['depth'].shape[1:])\n",
    "grads_size = tuple(sample_batch['x'].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] - default optimizer set: SGD(lr=0.001,momentum=0.9,weight_decay=0.0005)\n",
      "[I] - default scheduler set: StepSR(step_size=1000,gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "fusenetmodel = SpecialFuseNetModel(rgb_size=rgb_size,depth_size=depth_size,grads_size=grads_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = FuseNetTrainer(model=fusenetmodel, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = 'checkpoints/special_fusenet'\n",
    "# if os.path.isfile(f'{checkpoint_file}.pt'):\n",
    "#     os.remove(f'{checkpoint_file}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = trainer.fit(dl_train, dl_test, early_stopping=400, print_every=10,\n",
    "#                   checkpoints=checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "x sum:\n",
      "0.0\n",
      "y\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y sum:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fusenetmodel.load_state_dict(torch.load(checkpoint_file + '.pt', map_location=device), strict=False)\n",
    "\n",
    "img_rgb = Image.open(DATASET_DIR + \"/rgb/0.png\")\n",
    "img_depth = Image.open(DATASET_DIR + \"/depth/0.png\")\n",
    "img_rgb_tensor = rgb_tf(img_rgb)\n",
    "img_depth_tensor = depth_tf(img_depth)\n",
    "img_rgb_tensor.unsqueeze_(0)\n",
    "img_depth_tensor.unsqueeze_(0)\n",
    "output = fusenetmodel(Variable(img_rgb_tensor), Variable(img_depth_tensor))\n",
    "\n",
    "output = output.cpu().detach().numpy()[0]\n",
    "print(\"x\")\n",
    "print(output[0])\n",
    "print(\"x sum:\")\n",
    "print(np.sum(output[0]))\n",
    "print(\"y\")\n",
    "print(output[1])\n",
    "print(\"y sum:\")\n",
    "print(np.sum(output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
